{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1. Load MNIST data and scale it (code provided). Estimate a neural network with: epochs =20, batch_size = 100, and one hidden layer with 400 neurons. Measure and report validation accuracy and estimation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 400\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 400\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Validation accuracy: 0.8736\n",
      "5 Batch accuracy: 0.89 Validation accuracy: 0.9216\n",
      "10 Batch accuracy: 0.92 Validation accuracy: 0.9344\n",
      "15 Batch accuracy: 0.94 Validation accuracy: 0.9426\n",
      "dnn with 1 layer takes 16.74s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "import time \n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 1 layer takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2. Try adding new layers: estimate two-layer model: [400,100] and a three-layer model [400,100,25], report time and validation accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "# Set-up two hiddne layers\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    \n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.9 Validation accuracy: 0.8794\n",
      "5 Batch accuracy: 0.92 Validation accuracy: 0.931\n",
      "10 Batch accuracy: 0.93 Validation accuracy: 0.9494\n",
      "15 Batch accuracy: 0.94 Validation accuracy: 0.9596\n",
      "dnn with 2 layer takes 20.42s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 2 layers takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 25\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=leaky_relu, name=\"hidden3\")\n",
    "    \n",
    "    logits = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.87 Validation accuracy: 0.8792\n",
      "5 Batch accuracy: 0.92 Validation accuracy: 0.9392\n",
      "10 Batch accuracy: 0.93 Validation accuracy: 0.956\n",
      "15 Batch accuracy: 0.95 Validation accuracy: 0.9656\n",
      "dnn with 3 layer takes 23.01s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 3 layers takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3: Build a long and narrow five-layer network with [100,80,60,40,20] neurons on the same data. Report accuracy and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 100\n",
    "n_hidden2 = 80\n",
    "n_hidden3 = 60\n",
    "n_hidden4 = 40\n",
    "n_hidden5 = 20\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "# Set-up two hiddne layers\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=leaky_relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=leaky_relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=leaky_relu, name=\"hidden5\")\n",
    "\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.77 Validation accuracy: 0.7872\n",
      "5 Batch accuracy: 0.94 Validation accuracy: 0.936\n",
      "10 Batch accuracy: 0.97 Validation accuracy: 0.957\n",
      "15 Batch accuracy: 0.95 Validation accuracy: 0.9624\n",
      "dnn with 5 layers takes 13.89s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 5 layers takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4: Estimate a neural network with: epochs = 20, batch_size = 100. Try to find approximately optimal number of neurons using randomize grid search. Draw 20 random numbers from the [20,1000] neuron space. Measure and report highest validation accuracy and estimation time of the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=3, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=100, activation=leaky_relu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[854, 314, 225, 959, 481, 450, 428, 342, 954, 304]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "a = [random.randint(200,1000) for _ in range(10)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_neurons=854 ...................................................\n",
      "0\tLast training batch loss: 0.114206\tAccuracy: 97.00%\n",
      "1\tLast training batch loss: 0.076683\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.049317\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.022383\tAccuracy: 100.00%\n",
      "4\tLast training batch loss: 0.137289\tAccuracy: 95.00%\n",
      "5\tLast training batch loss: 0.106348\tAccuracy: 96.00%\n",
      "6\tLast training batch loss: 0.047798\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 2.489443\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 1.386411\tAccuracy: 95.00%\n",
      "9\tLast training batch loss: 0.254281\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.654841\tAccuracy: 95.00%\n",
      "11\tLast training batch loss: 1.117679\tAccuracy: 96.00%\n",
      "12\tLast training batch loss: 0.178700\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 0.143237\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.242001\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.023544\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.439206\tAccuracy: 97.00%\n",
      "17\tLast training batch loss: 0.740744\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 1.206265\tAccuracy: 97.00%\n",
      "19\tLast training batch loss: 1.822752\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=854, total= 1.5min\n",
      "[CV] n_neurons=854 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tLast training batch loss: 0.128309\tAccuracy: 97.00%\n",
      "1\tLast training batch loss: 0.090703\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.123286\tAccuracy: 96.00%\n",
      "3\tLast training batch loss: 0.643929\tAccuracy: 86.00%\n",
      "4\tLast training batch loss: 0.241853\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 1.529591\tAccuracy: 87.00%\n",
      "6\tLast training batch loss: 0.187419\tAccuracy: 97.00%\n",
      "7\tLast training batch loss: 0.184723\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.009511\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.069282\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.216791\tAccuracy: 96.00%\n",
      "11\tLast training batch loss: 0.000948\tAccuracy: 100.00%\n",
      "12\tLast training batch loss: 0.337551\tAccuracy: 93.00%\n",
      "13\tLast training batch loss: 2.348550\tAccuracy: 95.00%\n",
      "14\tLast training batch loss: 1.269276\tAccuracy: 98.00%\n",
      "15\tLast training batch loss: 0.750924\tAccuracy: 96.00%\n",
      "16\tLast training batch loss: 0.332284\tAccuracy: 97.00%\n",
      "17\tLast training batch loss: 0.006970\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.413682\tAccuracy: 95.00%\n",
      "19\tLast training batch loss: 0.216205\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=854, total= 1.5min\n",
      "[CV] n_neurons=854 ...................................................\n",
      "0\tLast training batch loss: 0.130270\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.065436\tAccuracy: 98.00%\n",
      "2\tLast training batch loss: 0.103372\tAccuracy: 95.00%\n",
      "3\tLast training batch loss: 0.169109\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.124732\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.035587\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.069896\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 0.180437\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.204805\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.095172\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.862188\tAccuracy: 93.00%\n",
      "11\tLast training batch loss: 0.115114\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.049737\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.694688\tAccuracy: 97.00%\n",
      "14\tLast training batch loss: 1.488852\tAccuracy: 95.00%\n",
      "15\tLast training batch loss: 1.395986\tAccuracy: 96.00%\n",
      "16\tLast training batch loss: 0.001861\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.210606\tAccuracy: 96.00%\n",
      "18\tLast training batch loss: 0.044121\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 1.598584\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=854, total= 1.4min\n",
      "[CV] n_neurons=314 ...................................................\n",
      "0\tLast training batch loss: 0.084556\tAccuracy: 97.00%\n",
      "1\tLast training batch loss: 0.025948\tAccuracy: 100.00%\n",
      "2\tLast training batch loss: 0.051579\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.050728\tAccuracy: 99.00%\n",
      "4\tLast training batch loss: 0.059063\tAccuracy: 99.00%\n",
      "5\tLast training batch loss: 0.031181\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.062532\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.141510\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 0.120759\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.035186\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.094126\tAccuracy: 96.00%\n",
      "11\tLast training batch loss: 0.023477\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.012300\tAccuracy: 100.00%\n",
      "13\tLast training batch loss: 0.010290\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.011672\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.045562\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.148404\tAccuracy: 94.00%\n",
      "17\tLast training batch loss: 0.016997\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.071337\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.108741\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=314, total=  21.8s\n",
      "[CV] n_neurons=314 ...................................................\n",
      "0\tLast training batch loss: 0.161484\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.150729\tAccuracy: 94.00%\n",
      "2\tLast training batch loss: 0.048575\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.148777\tAccuracy: 93.00%\n",
      "4\tLast training batch loss: 0.101993\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.065045\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.113106\tAccuracy: 95.00%\n",
      "7\tLast training batch loss: 0.105953\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.006616\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.032252\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.077584\tAccuracy: 97.00%\n",
      "11\tLast training batch loss: 0.049172\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.097497\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 0.009055\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.073286\tAccuracy: 98.00%\n",
      "15\tLast training batch loss: 0.158679\tAccuracy: 96.00%\n",
      "16\tLast training batch loss: 0.005851\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.003261\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.023671\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.070608\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=314, total=  21.7s\n",
      "[CV] n_neurons=314 ...................................................\n",
      "0\tLast training batch loss: 0.151505\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.087642\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.104350\tAccuracy: 97.00%\n",
      "3\tLast training batch loss: 0.099285\tAccuracy: 98.00%\n",
      "4\tLast training batch loss: 0.010738\tAccuracy: 100.00%\n",
      "5\tLast training batch loss: 0.017335\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.056404\tAccuracy: 97.00%\n",
      "7\tLast training batch loss: 0.115269\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.004685\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.007416\tAccuracy: 100.00%\n",
      "10\tLast training batch loss: 0.011688\tAccuracy: 100.00%\n",
      "11\tLast training batch loss: 0.261780\tAccuracy: 97.00%\n",
      "12\tLast training batch loss: 0.049065\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.090239\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.005139\tAccuracy: 100.00%\n",
      "15\tLast training batch loss: 0.105719\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.008816\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.001622\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.085101\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.010497\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=314, total=  21.5s\n",
      "[CV] n_neurons=225 ...................................................\n",
      "0\tLast training batch loss: 0.141625\tAccuracy: 93.00%\n",
      "1\tLast training batch loss: 0.044032\tAccuracy: 99.00%\n",
      "2\tLast training batch loss: 0.023342\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.039012\tAccuracy: 99.00%\n",
      "4\tLast training batch loss: 0.089264\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.013880\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.088299\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.061518\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.059728\tAccuracy: 98.00%\n",
      "9\tLast training batch loss: 0.058472\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.217009\tAccuracy: 96.00%\n",
      "11\tLast training batch loss: 0.035219\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.096368\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 0.075981\tAccuracy: 98.00%\n",
      "14\tLast training batch loss: 0.008422\tAccuracy: 100.00%\n",
      "15\tLast training batch loss: 0.026656\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.036517\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.026905\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.013081\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.059656\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=225, total=  17.0s\n",
      "[CV] n_neurons=225 ...................................................\n",
      "0\tLast training batch loss: 0.206004\tAccuracy: 94.00%\n",
      "1\tLast training batch loss: 0.132461\tAccuracy: 95.00%\n",
      "2\tLast training batch loss: 0.078522\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.131702\tAccuracy: 95.00%\n",
      "4\tLast training batch loss: 0.080075\tAccuracy: 96.00%\n",
      "5\tLast training batch loss: 0.026753\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.129966\tAccuracy: 97.00%\n",
      "7\tLast training batch loss: 0.081267\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 0.025451\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.069717\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.040424\tAccuracy: 99.00%\n",
      "11\tLast training batch loss: 0.043481\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.062291\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 0.038018\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.015420\tAccuracy: 99.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tLast training batch loss: 0.011743\tAccuracy: 100.00%\n",
      "16\tLast training batch loss: 0.004094\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.012326\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.030771\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.020474\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=225, total=  17.5s\n",
      "[CV] n_neurons=225 ...................................................\n",
      "0\tLast training batch loss: 0.124013\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.197797\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.095004\tAccuracy: 98.00%\n",
      "3\tLast training batch loss: 0.062106\tAccuracy: 98.00%\n",
      "4\tLast training batch loss: 0.056698\tAccuracy: 98.00%\n",
      "5\tLast training batch loss: 0.008585\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.088867\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.066122\tAccuracy: 99.00%\n",
      "8\tLast training batch loss: 0.006340\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.040485\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.039221\tAccuracy: 100.00%\n",
      "11\tLast training batch loss: 0.034334\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.011982\tAccuracy: 100.00%\n",
      "13\tLast training batch loss: 0.041591\tAccuracy: 98.00%\n",
      "14\tLast training batch loss: 0.212665\tAccuracy: 96.00%\n",
      "15\tLast training batch loss: 0.029190\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.000711\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.005179\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.000533\tAccuracy: 100.00%\n",
      "19\tLast training batch loss: 0.011366\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=225, total=  16.8s\n",
      "[CV] n_neurons=959 ...................................................\n",
      "0\tLast training batch loss: 0.126293\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.074874\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.052113\tAccuracy: 98.00%\n",
      "3\tLast training batch loss: 0.104147\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.073223\tAccuracy: 98.00%\n",
      "5\tLast training batch loss: 0.030917\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 27.067530\tAccuracy: 79.00%\n",
      "7\tLast training batch loss: 1.228126\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 2.630810\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.024837\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 1.564105\tAccuracy: 94.00%\n",
      "11\tLast training batch loss: 0.118324\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.573393\tAccuracy: 96.00%\n",
      "13\tLast training batch loss: 0.805554\tAccuracy: 93.00%\n",
      "14\tLast training batch loss: 0.026495\tAccuracy: 98.00%\n",
      "15\tLast training batch loss: 0.587761\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.463729\tAccuracy: 97.00%\n",
      "17\tLast training batch loss: 0.000083\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.115062\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 6.971571\tAccuracy: 92.00%\n",
      "[CV] .................................... n_neurons=959, total= 1.7min\n",
      "[CV] n_neurons=959 ...................................................\n",
      "0\tLast training batch loss: 0.152534\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.116352\tAccuracy: 95.00%\n",
      "2\tLast training batch loss: 0.073205\tAccuracy: 97.00%\n",
      "3\tLast training batch loss: 0.302424\tAccuracy: 91.00%\n",
      "4\tLast training batch loss: 0.168513\tAccuracy: 94.00%\n",
      "5\tLast training batch loss: 0.113648\tAccuracy: 97.00%\n",
      "6\tLast training batch loss: 0.174403\tAccuracy: 97.00%\n",
      "7\tLast training batch loss: 0.648378\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.617601\tAccuracy: 95.00%\n",
      "9\tLast training batch loss: 1.149565\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.719258\tAccuracy: 97.00%\n",
      "11\tLast training batch loss: 0.294328\tAccuracy: 97.00%\n",
      "12\tLast training batch loss: 0.787505\tAccuracy: 95.00%\n",
      "13\tLast training batch loss: 0.253833\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 9.896399\tAccuracy: 92.00%\n",
      "15\tLast training batch loss: 0.795872\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.316683\tAccuracy: 97.00%\n",
      "17\tLast training batch loss: 0.506228\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 0.109001\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.000906\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=959, total= 1.8min\n",
      "[CV] n_neurons=959 ...................................................\n",
      "0\tLast training batch loss: 0.103556\tAccuracy: 98.00%\n",
      "1\tLast training batch loss: 0.123174\tAccuracy: 95.00%\n",
      "2\tLast training batch loss: 0.377220\tAccuracy: 91.00%\n",
      "3\tLast training batch loss: 0.151121\tAccuracy: 96.00%\n",
      "4\tLast training batch loss: 0.457057\tAccuracy: 95.00%\n",
      "5\tLast training batch loss: 0.155181\tAccuracy: 94.00%\n",
      "6\tLast training batch loss: 1.146267\tAccuracy: 96.00%\n",
      "7\tLast training batch loss: 1.252206\tAccuracy: 94.00%\n",
      "8\tLast training batch loss: 0.027832\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.000091\tAccuracy: 100.00%\n",
      "10\tLast training batch loss: 0.002015\tAccuracy: 100.00%\n",
      "11\tLast training batch loss: 0.191887\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.080513\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 4.217446\tAccuracy: 90.00%\n",
      "14\tLast training batch loss: 0.519839\tAccuracy: 97.00%\n",
      "15\tLast training batch loss: 0.246429\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.000278\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 6.362507\tAccuracy: 96.00%\n",
      "18\tLast training batch loss: 0.181135\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.000004\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=959, total= 1.7min\n",
      "[CV] n_neurons=481 ...................................................\n",
      "0\tLast training batch loss: 0.208229\tAccuracy: 93.00%\n",
      "1\tLast training batch loss: 0.065017\tAccuracy: 99.00%\n",
      "2\tLast training batch loss: 0.014809\tAccuracy: 100.00%\n",
      "3\tLast training batch loss: 0.080213\tAccuracy: 98.00%\n",
      "4\tLast training batch loss: 0.118018\tAccuracy: 96.00%\n",
      "5\tLast training batch loss: 0.025383\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.166971\tAccuracy: 96.00%\n",
      "7\tLast training batch loss: 0.174742\tAccuracy: 95.00%\n",
      "8\tLast training batch loss: 0.078111\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.060794\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.140402\tAccuracy: 95.00%\n",
      "11\tLast training batch loss: 0.080428\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.033653\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.090937\tAccuracy: 95.00%\n",
      "14\tLast training batch loss: 0.140783\tAccuracy: 98.00%\n",
      "15\tLast training batch loss: 0.049640\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.102001\tAccuracy: 96.00%\n",
      "17\tLast training batch loss: 0.140485\tAccuracy: 98.00%\n",
      "18\tLast training batch loss: 2.074469\tAccuracy: 95.00%\n",
      "19\tLast training batch loss: 0.459387\tAccuracy: 96.00%\n",
      "[CV] .................................... n_neurons=481, total=  37.9s\n",
      "[CV] n_neurons=481 ...................................................\n",
      "0\tLast training batch loss: 0.199195\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.114443\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.112061\tAccuracy: 98.00%\n",
      "3\tLast training batch loss: 0.103002\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.108169\tAccuracy: 96.00%\n",
      "5\tLast training batch loss: 0.037198\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.054522\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.078559\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.046748\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.105568\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.018889\tAccuracy: 100.00%\n",
      "11\tLast training batch loss: 0.020769\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.111888\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 0.097326\tAccuracy: 97.00%\n",
      "14\tLast training batch loss: 0.084958\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.163818\tAccuracy: 97.00%\n",
      "16\tLast training batch loss: 0.009401\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.079625\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.149158\tAccuracy: 96.00%\n",
      "19\tLast training batch loss: 0.011175\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=481, total=  34.7s\n",
      "[CV] n_neurons=481 ...................................................\n",
      "0\tLast training batch loss: 0.153668\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.053871\tAccuracy: 99.00%\n",
      "2\tLast training batch loss: 0.197122\tAccuracy: 94.00%\n",
      "3\tLast training batch loss: 0.141204\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.080549\tAccuracy: 98.00%\n",
      "5\tLast training batch loss: 0.043254\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.053712\tAccuracy: 98.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\tLast training batch loss: 0.258909\tAccuracy: 94.00%\n",
      "8\tLast training batch loss: 0.000573\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.022138\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.072710\tAccuracy: 97.00%\n",
      "11\tLast training batch loss: 0.205445\tAccuracy: 95.00%\n",
      "12\tLast training batch loss: 0.002122\tAccuracy: 100.00%\n",
      "13\tLast training batch loss: 0.124242\tAccuracy: 98.00%\n",
      "14\tLast training batch loss: 0.012504\tAccuracy: 100.00%\n",
      "15\tLast training batch loss: 0.020698\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.113475\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.131405\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 0.476207\tAccuracy: 96.00%\n",
      "19\tLast training batch loss: 0.297811\tAccuracy: 97.00%\n",
      "[CV] .................................... n_neurons=481, total=  34.9s\n",
      "[CV] n_neurons=450 ...................................................\n",
      "0\tLast training batch loss: 0.155601\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.104079\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.024616\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.014987\tAccuracy: 100.00%\n",
      "4\tLast training batch loss: 0.096917\tAccuracy: 96.00%\n",
      "5\tLast training batch loss: 0.077000\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.051126\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.032685\tAccuracy: 99.00%\n",
      "8\tLast training batch loss: 0.087969\tAccuracy: 98.00%\n",
      "9\tLast training batch loss: 0.065575\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.194682\tAccuracy: 94.00%\n",
      "11\tLast training batch loss: 0.028873\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.055249\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 0.006201\tAccuracy: 100.00%\n",
      "14\tLast training batch loss: 0.023974\tAccuracy: 100.00%\n",
      "15\tLast training batch loss: 0.052625\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.792786\tAccuracy: 93.00%\n",
      "17\tLast training batch loss: 0.067036\tAccuracy: 98.00%\n",
      "18\tLast training batch loss: 0.164380\tAccuracy: 97.00%\n",
      "19\tLast training batch loss: 0.114656\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=450, total=  32.2s\n",
      "[CV] n_neurons=450 ...................................................\n",
      "0\tLast training batch loss: 0.126395\tAccuracy: 97.00%\n",
      "1\tLast training batch loss: 0.121176\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.070788\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.158596\tAccuracy: 95.00%\n",
      "4\tLast training batch loss: 0.167255\tAccuracy: 95.00%\n",
      "5\tLast training batch loss: 0.027247\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.055068\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 0.040844\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.017688\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.179800\tAccuracy: 96.00%\n",
      "10\tLast training batch loss: 0.582910\tAccuracy: 90.00%\n",
      "11\tLast training batch loss: 0.049294\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.118762\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 0.196265\tAccuracy: 96.00%\n",
      "14\tLast training batch loss: 0.215820\tAccuracy: 97.00%\n",
      "15\tLast training batch loss: 0.088378\tAccuracy: 97.00%\n",
      "16\tLast training batch loss: 0.012171\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.151455\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.024461\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.116223\tAccuracy: 97.00%\n",
      "[CV] .................................... n_neurons=450, total=  31.9s\n",
      "[CV] n_neurons=450 ...................................................\n",
      "0\tLast training batch loss: 0.127652\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.084754\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.071284\tAccuracy: 97.00%\n",
      "3\tLast training batch loss: 0.061972\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.080211\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.209222\tAccuracy: 95.00%\n",
      "6\tLast training batch loss: 0.090287\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.211108\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 0.004481\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.003147\tAccuracy: 100.00%\n",
      "10\tLast training batch loss: 0.008011\tAccuracy: 100.00%\n",
      "11\tLast training batch loss: 0.033893\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.012942\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.221439\tAccuracy: 96.00%\n",
      "14\tLast training batch loss: 0.087554\tAccuracy: 97.00%\n",
      "15\tLast training batch loss: 0.009739\tAccuracy: 100.00%\n",
      "16\tLast training batch loss: 0.073269\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.005776\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.042012\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.007446\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=450, total=  31.8s\n",
      "[CV] n_neurons=428 ...................................................\n",
      "0\tLast training batch loss: 0.231275\tAccuracy: 93.00%\n",
      "1\tLast training batch loss: 0.184055\tAccuracy: 95.00%\n",
      "2\tLast training batch loss: 0.028115\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.075162\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.029837\tAccuracy: 99.00%\n",
      "5\tLast training batch loss: 0.076085\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.013052\tAccuracy: 100.00%\n",
      "7\tLast training batch loss: 0.080066\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 0.119772\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.255760\tAccuracy: 96.00%\n",
      "10\tLast training batch loss: 0.181016\tAccuracy: 94.00%\n",
      "11\tLast training batch loss: 0.014140\tAccuracy: 100.00%\n",
      "12\tLast training batch loss: 0.027915\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.024351\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.028148\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.017454\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.226299\tAccuracy: 94.00%\n",
      "17\tLast training batch loss: 0.206365\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 0.078265\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.121998\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=428, total=  30.2s\n",
      "[CV] n_neurons=428 ...................................................\n",
      "0\tLast training batch loss: 0.135459\tAccuracy: 98.00%\n",
      "1\tLast training batch loss: 0.137296\tAccuracy: 95.00%\n",
      "2\tLast training batch loss: 0.067951\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.076508\tAccuracy: 96.00%\n",
      "4\tLast training batch loss: 0.097049\tAccuracy: 98.00%\n",
      "5\tLast training batch loss: 0.043986\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.076819\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.045106\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.039585\tAccuracy: 98.00%\n",
      "9\tLast training batch loss: 0.110208\tAccuracy: 96.00%\n",
      "10\tLast training batch loss: 0.039920\tAccuracy: 99.00%\n",
      "11\tLast training batch loss: 0.011514\tAccuracy: 100.00%\n",
      "12\tLast training batch loss: 0.120670\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 1.483766\tAccuracy: 94.00%\n",
      "14\tLast training batch loss: 0.409305\tAccuracy: 96.00%\n",
      "15\tLast training batch loss: 0.054601\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.026630\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.026432\tAccuracy: 98.00%\n",
      "18\tLast training batch loss: 0.266343\tAccuracy: 96.00%\n",
      "19\tLast training batch loss: 0.025102\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=428, total=  29.9s\n",
      "[CV] n_neurons=428 ...................................................\n",
      "0\tLast training batch loss: 0.170303\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.117760\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.144034\tAccuracy: 95.00%\n",
      "3\tLast training batch loss: 0.053608\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.037786\tAccuracy: 98.00%\n",
      "5\tLast training batch loss: 0.022070\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.052896\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 0.125750\tAccuracy: 97.00%\n",
      "8\tLast training batch loss: 0.011493\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.007183\tAccuracy: 100.00%\n",
      "10\tLast training batch loss: 0.028490\tAccuracy: 99.00%\n",
      "11\tLast training batch loss: 0.008353\tAccuracy: 100.00%\n",
      "12\tLast training batch loss: 0.079544\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 0.049252\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.068967\tAccuracy: 98.00%\n",
      "15\tLast training batch loss: 0.012371\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.019856\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.007902\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.105427\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.344179\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=428, total=  30.2s\n",
      "[CV] n_neurons=342 ...................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tLast training batch loss: 0.084406\tAccuracy: 98.00%\n",
      "1\tLast training batch loss: 0.063944\tAccuracy: 98.00%\n",
      "2\tLast training batch loss: 0.034293\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.052329\tAccuracy: 98.00%\n",
      "4\tLast training batch loss: 0.043160\tAccuracy: 100.00%\n",
      "5\tLast training batch loss: 0.040731\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.092132\tAccuracy: 97.00%\n",
      "7\tLast training batch loss: 0.082004\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.136314\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.066306\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.085166\tAccuracy: 97.00%\n",
      "11\tLast training batch loss: 0.098136\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.034814\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 0.111521\tAccuracy: 97.00%\n",
      "14\tLast training batch loss: 0.028654\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.004516\tAccuracy: 100.00%\n",
      "16\tLast training batch loss: 0.157538\tAccuracy: 96.00%\n",
      "17\tLast training batch loss: 0.049735\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 0.002886\tAccuracy: 100.00%\n",
      "19\tLast training batch loss: 0.022202\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=342, total=  24.0s\n",
      "[CV] n_neurons=342 ...................................................\n",
      "0\tLast training batch loss: 0.175821\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.160770\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.041681\tAccuracy: 98.00%\n",
      "3\tLast training batch loss: 0.086583\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.079670\tAccuracy: 99.00%\n",
      "5\tLast training batch loss: 0.085485\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.064848\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 0.115196\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.093685\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.048403\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.047342\tAccuracy: 98.00%\n",
      "11\tLast training batch loss: 0.004477\tAccuracy: 100.00%\n",
      "12\tLast training batch loss: 0.035852\tAccuracy: 100.00%\n",
      "13\tLast training batch loss: 0.007083\tAccuracy: 100.00%\n",
      "14\tLast training batch loss: 0.019543\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.048292\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.008956\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.129083\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.005631\tAccuracy: 100.00%\n",
      "19\tLast training batch loss: 0.077872\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=342, total=  25.3s\n",
      "[CV] n_neurons=342 ...................................................\n",
      "0\tLast training batch loss: 0.100402\tAccuracy: 97.00%\n",
      "1\tLast training batch loss: 0.195195\tAccuracy: 95.00%\n",
      "2\tLast training batch loss: 0.087303\tAccuracy: 97.00%\n",
      "3\tLast training batch loss: 0.074954\tAccuracy: 98.00%\n",
      "4\tLast training batch loss: 0.103753\tAccuracy: 99.00%\n",
      "5\tLast training batch loss: 0.042271\tAccuracy: 99.00%\n",
      "6\tLast training batch loss: 0.047173\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.096773\tAccuracy: 96.00%\n",
      "8\tLast training batch loss: 0.008291\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.006529\tAccuracy: 100.00%\n",
      "10\tLast training batch loss: 0.036035\tAccuracy: 99.00%\n",
      "11\tLast training batch loss: 0.033017\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.069817\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 0.009436\tAccuracy: 100.00%\n",
      "14\tLast training batch loss: 0.016699\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.083875\tAccuracy: 95.00%\n",
      "16\tLast training batch loss: 0.077640\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.009946\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.012727\tAccuracy: 100.00%\n",
      "19\tLast training batch loss: 0.073988\tAccuracy: 99.00%\n",
      "[CV] .................................... n_neurons=342, total=  24.8s\n",
      "[CV] n_neurons=954 ...................................................\n",
      "0\tLast training batch loss: 0.324315\tAccuracy: 89.00%\n",
      "1\tLast training batch loss: 0.083214\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.040516\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.022517\tAccuracy: 99.00%\n",
      "4\tLast training batch loss: 0.088895\tAccuracy: 96.00%\n",
      "5\tLast training batch loss: 0.265910\tAccuracy: 96.00%\n",
      "6\tLast training batch loss: 0.510418\tAccuracy: 96.00%\n",
      "7\tLast training batch loss: 0.135444\tAccuracy: 99.00%\n",
      "8\tLast training batch loss: 3.260255\tAccuracy: 94.00%\n",
      "9\tLast training batch loss: 1.468229\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.580553\tAccuracy: 96.00%\n",
      "11\tLast training batch loss: 0.832771\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.824625\tAccuracy: 96.00%\n",
      "13\tLast training batch loss: 0.971920\tAccuracy: 96.00%\n",
      "14\tLast training batch loss: 0.365083\tAccuracy: 98.00%\n",
      "15\tLast training batch loss: 0.194931\tAccuracy: 98.00%\n",
      "16\tLast training batch loss: 0.892151\tAccuracy: 96.00%\n",
      "17\tLast training batch loss: 0.948028\tAccuracy: 96.00%\n",
      "18\tLast training batch loss: 4.161397\tAccuracy: 96.00%\n",
      "19\tLast training batch loss: 4.754261\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=954, total= 1.7min\n",
      "[CV] n_neurons=954 ...................................................\n",
      "0\tLast training batch loss: 0.182310\tAccuracy: 94.00%\n",
      "1\tLast training batch loss: 0.187345\tAccuracy: 94.00%\n",
      "2\tLast training batch loss: 0.081185\tAccuracy: 96.00%\n",
      "3\tLast training batch loss: 0.122203\tAccuracy: 96.00%\n",
      "4\tLast training batch loss: 0.053746\tAccuracy: 99.00%\n",
      "5\tLast training batch loss: 3.853883\tAccuracy: 92.00%\n",
      "6\tLast training batch loss: 1.489992\tAccuracy: 92.00%\n",
      "7\tLast training batch loss: 0.730486\tAccuracy: 93.00%\n",
      "8\tLast training batch loss: 0.008859\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.353398\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.148408\tAccuracy: 97.00%\n",
      "11\tLast training batch loss: 0.164569\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.225908\tAccuracy: 98.00%\n",
      "13\tLast training batch loss: 0.483759\tAccuracy: 96.00%\n",
      "14\tLast training batch loss: 1.265664\tAccuracy: 95.00%\n",
      "15\tLast training batch loss: 1.508332\tAccuracy: 96.00%\n",
      "16\tLast training batch loss: 0.103874\tAccuracy: 99.00%\n",
      "17\tLast training batch loss: 0.177110\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.000144\tAccuracy: 100.00%\n",
      "19\tLast training batch loss: 0.000372\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=954, total= 1.7min\n",
      "[CV] n_neurons=954 ...................................................\n",
      "0\tLast training batch loss: 0.125580\tAccuracy: 95.00%\n",
      "1\tLast training batch loss: 0.114497\tAccuracy: 98.00%\n",
      "2\tLast training batch loss: 0.249675\tAccuracy: 93.00%\n",
      "3\tLast training batch loss: 1.006396\tAccuracy: 89.00%\n",
      "4\tLast training batch loss: 0.176420\tAccuracy: 96.00%\n",
      "5\tLast training batch loss: 0.121674\tAccuracy: 96.00%\n",
      "6\tLast training batch loss: 0.212056\tAccuracy: 97.00%\n",
      "7\tLast training batch loss: 0.358920\tAccuracy: 95.00%\n",
      "8\tLast training batch loss: 0.045569\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.319462\tAccuracy: 96.00%\n",
      "10\tLast training batch loss: 0.126301\tAccuracy: 98.00%\n",
      "11\tLast training batch loss: 1.607943\tAccuracy: 94.00%\n",
      "12\tLast training batch loss: 0.003354\tAccuracy: 100.00%\n",
      "13\tLast training batch loss: 2.048234\tAccuracy: 95.00%\n",
      "14\tLast training batch loss: 2.009893\tAccuracy: 96.00%\n",
      "15\tLast training batch loss: 0.737663\tAccuracy: 97.00%\n",
      "16\tLast training batch loss: 0.000000\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.000009\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.092454\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.305403\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=954, total= 1.7min\n",
      "[CV] n_neurons=304 ...................................................\n",
      "0\tLast training batch loss: 0.114042\tAccuracy: 93.00%\n",
      "1\tLast training batch loss: 0.073447\tAccuracy: 98.00%\n",
      "2\tLast training batch loss: 0.050928\tAccuracy: 99.00%\n",
      "3\tLast training batch loss: 0.051432\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.077388\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.059649\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.079738\tAccuracy: 96.00%\n",
      "7\tLast training batch loss: 0.048753\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.051953\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.070228\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.066222\tAccuracy: 98.00%\n",
      "11\tLast training batch loss: 0.054477\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.022310\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.048068\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.088749\tAccuracy: 98.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tLast training batch loss: 0.054441\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.053357\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.043452\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.062158\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.094773\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=304, total=  21.2s\n",
      "[CV] n_neurons=304 ...................................................\n",
      "0\tLast training batch loss: 0.147091\tAccuracy: 98.00%\n",
      "1\tLast training batch loss: 0.133367\tAccuracy: 96.00%\n",
      "2\tLast training batch loss: 0.061464\tAccuracy: 98.00%\n",
      "3\tLast training batch loss: 0.099957\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.051768\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.016409\tAccuracy: 100.00%\n",
      "6\tLast training batch loss: 0.293977\tAccuracy: 95.00%\n",
      "7\tLast training batch loss: 0.029524\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.009401\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.095306\tAccuracy: 98.00%\n",
      "10\tLast training batch loss: 0.037939\tAccuracy: 99.00%\n",
      "11\tLast training batch loss: 0.051288\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.111106\tAccuracy: 96.00%\n",
      "13\tLast training batch loss: 0.003437\tAccuracy: 100.00%\n",
      "14\tLast training batch loss: 0.010318\tAccuracy: 99.00%\n",
      "15\tLast training batch loss: 0.030221\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.003480\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.038429\tAccuracy: 99.00%\n",
      "18\tLast training batch loss: 0.029974\tAccuracy: 98.00%\n",
      "19\tLast training batch loss: 0.028650\tAccuracy: 98.00%\n",
      "[CV] .................................... n_neurons=304, total=  21.3s\n",
      "[CV] n_neurons=304 ...................................................\n",
      "0\tLast training batch loss: 0.125414\tAccuracy: 96.00%\n",
      "1\tLast training batch loss: 0.115316\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.134838\tAccuracy: 95.00%\n",
      "3\tLast training batch loss: 0.104905\tAccuracy: 97.00%\n",
      "4\tLast training batch loss: 0.029055\tAccuracy: 100.00%\n",
      "5\tLast training batch loss: 0.091777\tAccuracy: 97.00%\n",
      "6\tLast training batch loss: 0.029482\tAccuracy: 98.00%\n",
      "7\tLast training batch loss: 0.117587\tAccuracy: 95.00%\n",
      "8\tLast training batch loss: 0.002801\tAccuracy: 100.00%\n",
      "9\tLast training batch loss: 0.000816\tAccuracy: 100.00%\n",
      "10\tLast training batch loss: 0.014275\tAccuracy: 100.00%\n",
      "11\tLast training batch loss: 0.033865\tAccuracy: 99.00%\n",
      "12\tLast training batch loss: 0.005581\tAccuracy: 100.00%\n",
      "13\tLast training batch loss: 0.078132\tAccuracy: 98.00%\n",
      "14\tLast training batch loss: 0.115077\tAccuracy: 95.00%\n",
      "15\tLast training batch loss: 0.037765\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.015789\tAccuracy: 99.00%\n",
      "17\tLast training batch loss: 0.004605\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.012931\tAccuracy: 100.00%\n",
      "19\tLast training batch loss: 0.018084\tAccuracy: 100.00%\n",
      "[CV] .................................... n_neurons=304, total=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 24.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tLast training batch loss: 0.161759\tAccuracy: 94.00%\n",
      "1\tLast training batch loss: 0.109485\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.132083\tAccuracy: 97.00%\n",
      "3\tLast training batch loss: 0.038225\tAccuracy: 99.00%\n",
      "4\tLast training batch loss: 0.063873\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.065343\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.031937\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 0.039774\tAccuracy: 99.00%\n",
      "8\tLast training batch loss: 0.018023\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.045555\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.148827\tAccuracy: 96.00%\n",
      "11\tLast training batch loss: 0.037689\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.031276\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.047324\tAccuracy: 98.00%\n",
      "14\tLast training batch loss: 0.001200\tAccuracy: 100.00%\n",
      "15\tLast training batch loss: 0.087095\tAccuracy: 96.00%\n",
      "16\tLast training batch loss: 0.020970\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.141498\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 0.059647\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.194235\tAccuracy: 96.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function leaky_relu at 0xb18e4e268>,\n",
       "       batch_norm_momentum=None, batch_size=100, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1054146a0>,\n",
       "       learning_rate=0.01, n_hidden_layers=3, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_neurons': [854, 314, 225, 959, 481, 450, 428, 342, 954, 304]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [854, 314, 225, 959, 481, 450, 428, 342, 954, 304]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs,\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train, y_train,n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = rnd_search.predict(X_valid)\n",
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 314}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tLast training batch loss: 0.161759\tAccuracy: 94.00%\n",
      "1\tLast training batch loss: 0.109485\tAccuracy: 97.00%\n",
      "2\tLast training batch loss: 0.132083\tAccuracy: 97.00%\n",
      "3\tLast training batch loss: 0.038225\tAccuracy: 99.00%\n",
      "4\tLast training batch loss: 0.063873\tAccuracy: 97.00%\n",
      "5\tLast training batch loss: 0.065343\tAccuracy: 98.00%\n",
      "6\tLast training batch loss: 0.031937\tAccuracy: 99.00%\n",
      "7\tLast training batch loss: 0.039774\tAccuracy: 99.00%\n",
      "8\tLast training batch loss: 0.018023\tAccuracy: 99.00%\n",
      "9\tLast training batch loss: 0.045555\tAccuracy: 99.00%\n",
      "10\tLast training batch loss: 0.148827\tAccuracy: 96.00%\n",
      "11\tLast training batch loss: 0.037689\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.031276\tAccuracy: 99.00%\n",
      "13\tLast training batch loss: 0.047324\tAccuracy: 98.00%\n",
      "14\tLast training batch loss: 0.001200\tAccuracy: 100.00%\n",
      "15\tLast training batch loss: 0.087095\tAccuracy: 96.00%\n",
      "16\tLast training batch loss: 0.020970\tAccuracy: 100.00%\n",
      "17\tLast training batch loss: 0.141498\tAccuracy: 97.00%\n",
      "18\tLast training batch loss: 0.059647\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.194235\tAccuracy: 96.00%\n",
      "dnn with 314 neuron spaces takes 31.17s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "dnn_clf_bn = DNNClassifier(n_neurons=314, random_state=42)\n",
    "dnn_clf_bn.fit(X_train, y_train, n_epochs=20)\n",
    "t1 = time.time()\n",
    "print(\"dnn with 314 neuron spaces takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5.\n",
    "Go back to the baseline model 400 neurons one level. What is the time cost of increasing batch size by one observation? . What is the time cost of adding one more epoch? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 400\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Validation accuracy: 0.8736\n",
      "5 Batch accuracy: 0.89 Validation accuracy: 0.9216\n",
      "10 Batch accuracy: 0.92 Validation accuracy: 0.9344\n",
      "15 Batch accuracy: 0.94 Validation accuracy: 0.9426\n",
      "20 Batch accuracy: 0.95 Validation accuracy: 0.9482\n",
      "dnn with 1 more epoch takes 18.22s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 21\n",
    "batch_size = 100\n",
    "\n",
    "import time \n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 1 more epoch takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.8811881 Validation accuracy: 0.8724\n",
      "5 Batch accuracy: 0.9207921 Validation accuracy: 0.9224\n",
      "10 Batch accuracy: 0.96039605 Validation accuracy: 0.9354\n",
      "15 Batch accuracy: 0.9405941 Validation accuracy: 0.942\n",
      "dnn with 1 more batch takes 17.48s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 101\n",
    "\n",
    "import time \n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 1 more batch takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6. Find change in accuracy and time if you double your batch size to 200? Find change in accuracy and time if increase the number of epochs to 40? Which is the better approach? Report the gain the accuracy and the cost in time for each approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.865 Validation accuracy: 0.8392\n",
      "5 Batch accuracy: 0.87 Validation accuracy: 0.9062\n",
      "10 Batch accuracy: 0.91 Validation accuracy: 0.9214\n",
      "15 Batch accuracy: 0.925 Validation accuracy: 0.9288\n",
      "dnn with 200 batchs takes 14.13s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "import time \n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 200 batchs takes {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.88 Validation accuracy: 0.8726\n",
      "5 Batch accuracy: 0.89 Validation accuracy: 0.9228\n",
      "10 Batch accuracy: 0.96 Validation accuracy: 0.9352\n",
      "15 Batch accuracy: 0.92 Validation accuracy: 0.9428\n",
      "20 Batch accuracy: 0.95 Validation accuracy: 0.9498\n",
      "25 Batch accuracy: 0.91 Validation accuracy: 0.9534\n",
      "30 Batch accuracy: 0.89 Validation accuracy: 0.9568\n",
      "35 Batch accuracy: 0.96 Validation accuracy: 0.9602\n",
      "dnn with 40 epochs takes 33.89s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 100\n",
    "\n",
    "import time \n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "t1 = time.time()\n",
    "print(\"dnn with 40 epochs takes {:.2f}s\".format(t1 - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
